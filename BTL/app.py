# app.py
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import joblib
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

sns.set_style("whitegrid")

# ======================
# 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
# ======================
def clean_text(s):
    if not isinstance(s, str):
        return ""
    s = s.lower()
    s = re.sub(r"http\S+|www\S+|https\S+", " ", s)     # URL
    s = re.sub(r"\S+@\S+", " ", s)                     # Email
    s = re.sub(r"\+?\d[\d\s\-]{5,}\d", " ", s)         # Sá»‘ Ä‘iá»‡n thoáº¡i
    s = re.sub(r"[^a-z0-9\s]", " ", s)                 # KÃ½ tá»± Ä‘áº·c biá»‡t
    s = re.sub(r"\s+", " ", s).strip()
    return s

def load_and_prepare(path):
    df = pd.read_csv(path, encoding="utf-8")
    df['text'] = df['sms']  # Ä‘á»“ng nháº¥t cá»™t dÃ¹ng cho pipeline
    df['text_clean'] = df['sms'].apply(clean_text)
    df['len_char'] = df['sms'].apply(lambda x: len(str(x)))
    df['len_word'] = df['sms'].apply(lambda x: len(str(x).split()))
    df['has_number'] = df['sms'].str.contains(r"\d").astype(int)
    df['has_special'] = df['sms'].str.contains(r"[^a-zA-Z0-9\s]").astype(int)
    return df

# ======================
# 2. EDA (hiá»ƒn thá»‹ trong Streamlit)
# ======================
def exploratory_data_analysis_streamlit(df):
    # PhÃ¢n bá»‘ nhÃ£n
    label_counts = df['label'].value_counts().sort_index()
    label_percent = (label_counts / label_counts.sum() * 100).round(2)

    st.subheader("ğŸ“Š PhÃ¢n bá»‘ nhÃ£n (Count & Percent)")
    label_df = pd.DataFrame({
        "Label": label_counts.index.astype(str),
        "Count": label_counts.values,
        "Percent (%)": label_percent.values
    }).set_index("Label")
    st.table(label_df)

    # Biá»ƒu Ä‘á»“ cá»™t (Count)
    fig, ax = plt.subplots(figsize=(4,3))
    sns.barplot(x=label_counts.index.astype(str), y=label_counts.values, palette="viridis", ax=ax)
    ax.set_title("Sá»‘ lÆ°á»£ng theo nhÃ£n")
    ax.set_xlabel("Label (0 = Ham, 1 = Spam)")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    st.pyplot(fig)

    # Biá»ƒu Ä‘á»“ bÃ¡nh (Percent)
    fig2, ax2 = plt.subplots(figsize=(4,3))
    colors = ["#4CAF50", "#F44336"] if len(label_percent) == 2 else None
    ax2.pie(label_percent.values, labels=label_percent.index.astype(str),
            autopct='%1.1f%%', startangle=90, colors=colors)
    ax2.set_title("Tá»· lá»‡ pháº§n trÄƒm theo nhÃ£n")
    ax2.axis('equal')
    st.pyplot(fig2)

    # Äá»™ dÃ i tin nháº¯n
    df['msg_len'] = df['text'].apply(len)
    st.subheader("ğŸ“ˆ PhÃ¢n phá»‘i Ä‘á»™ dÃ i tin nháº¯n")
    fig3, ax3 = plt.subplots(figsize=(4,3))
    sns.histplot(df['msg_len'], bins=50, kde=True, ax=ax3)
    ax3.set_xlabel("Äá»™ dÃ i tin nháº¯n")
    ax3.set_ylabel("Táº§n suáº¥t")
    st.pyplot(fig3)

    # Boxplot
    st.subheader("ğŸ“¦ Boxplot Ä‘á»™ dÃ i theo nhÃ£n")
    fig4, ax4 = plt.subplots(figsize=(4,3))
    sns.boxplot(x='label', y='msg_len', data=df, palette="Set2", ax=ax4)
    ax4.set_xlabel("Label")
    ax4.set_ylabel("Äá»™ dÃ i tin nháº¯n")
    st.pyplot(fig4)

    # Top tá»«
    st.subheader("ğŸ”¤ Top 20 tá»« phá»• biáº¿n (chÆ°a loáº¡i stopwords)")
    all_words = " ".join(df['text_clean']).split()
    word_counts = Counter(all_words)
    common_words = word_counts.most_common(20)
    if common_words:
        words, counts = zip(*common_words)
        fig5, ax5 = plt.subplots(figsize=(5,3.5))
        sns.barplot(x=list(counts), y=list(words), palette="mako", ax=ax5)
        ax5.set_xlabel("Táº§n suáº¥t")
        ax5.set_ylabel("Tá»«")
        st.pyplot(fig5)

    # Tá»· lá»‡ chá»©a sá»‘ / kÃ½ tá»± Ä‘áº·c biá»‡t
    st.subheader("ğŸ” Tá»· lá»‡ chá»©a sá»‘ / kÃ½ tá»± Ä‘áº·c biá»‡t theo nhÃ£n")
    st.write(df.groupby('label')[['has_number', 'has_special']].mean().round(4))

    # BÃ¡o cÃ¡o tá»± Ä‘á»™ng ngáº¯n
    st.subheader("ğŸ“‘ BÃ¡o cÃ¡o EDA tá»± Ä‘á»™ng (tÃ³m táº¯t)")
    report = []
    if label_percent.min() < 30:
        report.append("âš ï¸ Dá»¯ liá»‡u bá»‹ máº¥t cÃ¢n báº±ng nhÃ£n, cÃ¢n nháº¯c oversampling/undersampling.")
    else:
        report.append("âœ… Dá»¯ liá»‡u phÃ¢n bá»‘ khÃ¡ cÃ¢n báº±ng giá»¯a cÃ¡c nhÃ£n.")
    report.append("ğŸ“ˆ Tin nháº¯n thÆ°á»ng ngáº¯n (<200 kÃ½ tá»±).")
    report.append("ğŸ“¦ Spam cÃ³ xu hÆ°á»›ng dÃ i hÆ¡n ham.")
    report.append("ğŸ” Spam cÃ³ xu hÆ°á»›ng chá»©a nhiá»u sá»‘/kÃ½ tá»± Ä‘áº·c biá»‡t hÆ¡n ham.")
    for r in report:
        st.markdown("- " + r)

# ======================
# 3. Huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡
# ======================
def train_and_evaluate(models, X_train, X_test, y_train, y_test):
    results = []
    cms = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        results.append({"MÃ´ hÃ¬nh": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1-score": f1})
        cms[name] = confusion_matrix(y_test, y_pred)
    return pd.DataFrame(results), cms

# ======================
# Main pipeline (cháº¡y khi start app)
# ======================
file_path = "BTL/data/train.csv" #"E:/DangVanThanh/train.csv"   # sá»­a náº¿u cáº§n
df = load_and_prepare(file_path)

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.9, ngram_range=(1,2))
X = tfidf.fit_transform(df['text_clean'])
y = df['label'].values

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

models = {
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),
    "Naive Bayes": MultinomialNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42)
}
results_df, cms = train_and_evaluate(models, X_train, X_test, y_train, y_test)

# LÆ°u TF-IDF vÃ  best model
joblib.dump(tfidf, "tfidf_vectorizer.pkl")
best_model_name = results_df.sort_values(by="F1-score", ascending=False).iloc[0]["MÃ´ hÃ¬nh"]
best_model = models[best_model_name]
joblib.dump(best_model, "best_model.pkl")

# ======================
# Streamlit UI: 3 tab
# ======================
st.set_page_config(page_title="Spam SMS Detector", layout="centered")
tab1, tab2, tab3 = st.tabs(["ğŸ“Š KhÃ¡m phÃ¡ dá»¯ liá»‡u", "ğŸ¤– Káº¿t quáº£ mÃ´ hÃ¬nh", "ğŸ“© Dá»± Ä‘oÃ¡n Spam/Ham"])

with tab1:
    st.header("ğŸ“Š KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA)")
    exploratory_data_analysis_streamlit(df)

with tab2:
    st.header("ğŸ¤– Káº¿t quáº£ mÃ´ hÃ¬nh")
    st.dataframe(results_df.sort_values(by="F1-score", ascending=False).reset_index(drop=True))
    for name, cm in cms.items():
        st.subheader(f"Confusion Matrix - {name}")
        fig_cm, ax_cm = plt.subplots(figsize=(4,3))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                    xticklabels=["Ham (0)", "Spam (1)"],
                    yticklabels=["Ham (0)", "Spam (1)"],
                    ax=ax_cm)
        st.pyplot(fig_cm)

with tab3:
    st.header("ğŸ“© Dá»± Ä‘oÃ¡n Spam/Ham")
    tfidf = joblib.load("tfidf_vectorizer.pkl")
    model = joblib.load("best_model.pkl")

    sms = st.text_area("Nháº­p tin nháº¯n:", height=150)
    if st.button("Dá»± Ä‘oÃ¡n"):
        if sms.strip() == "":
            st.warning("Báº¡n chÆ°a nháº­p tin nháº¯n!")
        else:
            sms_clean = clean_text(sms)
            X_new = tfidf.transform([sms_clean])
            y_pred = model.predict(X_new)[0]
            prob = None
            if hasattr(model, "predict_proba"):
                prob = model.predict_proba(X_new).max()
            if int(y_pred) == 1:
                st.error(f"ğŸš¨ Spam ({'%.2f'% (prob*100) + '%' if prob is not None else ''})")
            else:
                st.success(f"âœ… Ham ({'%.2f'% (prob*100) + '%' if prob is not None else ''})")
